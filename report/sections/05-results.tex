\section{Results}

\subsection{Quantitative Analysis}

\begin{figure*}
\centering
\includegraphics[height=50ex]{graphics/combined-violations-plt}
% \includegraphics[height=50ex]{graphics/violations-unit-plt}
% \includegraphics[height=50ex]{graphics/violations-all-plt}
\caption{Violations per version. ``jsapi'' is a subset of violations found in ``all''}
\label{fig:violations}
\end{figure*}

First we wanted to show that we could find any violations at all using
test. Figure~\ref{fig:violations} is a plot of violations encounter in
each version. The ``jsapi'' suite is a subset of the test run in ``all''.
Since a SemVer violation is tied to a test and a implementation version, 
the same test might be counted multiple times. From the figure we can
read a lot of interesting things. The versions 1.3.0, 1.15.0 and 1.18.0 are
especially interesting as they introduce new breaking changes in respect to
``jsapi''.  The 1.3.0 increment is a single violation is analysed in depth in
section~\ref{sec:failure2}. The 1.15.0 increment is mostly due the SemVer
violation that we found in and described in section~\ref{sec:failure3}. The
1.18.0 is increment is not a SemVer violation, as it seams like the developers
tested secrets in the jsapi. This has been described in detail in
section~\ref{sec:failure1}. The steep increase in breaking changes 1.21.5 could
indicate that they were working on creating the new major release, and some of
the new features; green and yellow, and some breaking changes might have
sneaked in. It is interesting that after the major version 2, almost no breaking
changes exist in ``jsapi''. This suggest that the API tests has matured, and
are more stable. A funny anomaly happened in v2.5.0 where the npm stopped
working on that package.

This analysis shows that even with test not designed to be interface
specifications, we can get real and relevant information about the progress in



\begin{figure*}
\centering
\includegraphics[height=50ex]{graphics/combined-cumulative-plt}
%\includegraphics[height=50ex]{graphics/cumulative-unit-plt}
%\includegraphics[height=50ex]{graphics/cumulative-all-plt}
\caption{Violations per version}
\end{figure*}

\begin{figure*}
\centering
\includegraphics[height=50ex]{graphics/simulation-plt}
%\includegraphics[height=50ex]{graphics/cumulative-unit-plt}
%\includegraphics[height=50ex]{graphics/cumulative-all-plt}
\caption{Violations per version}
\end{figure*}

\subsection{User Study Results}
We used the test suite of mocha as our subject program. The developers
identify the ``jsapi'' test suite, comprising 66 tests, as their
``interface tests''. Some of these test methods that are annotated
{\tt @api private}, which might indicate that these methods are not
part of the client-facing API\@. However, judging from the
documentation, it seems that these are treated more as advanced
features that clients may want to use in rare cases, but most of the
time can safely ignore. We decided to use all the ``jsapi'' tests as the
interface spec because 1) it is unclear which of the {\tt @api
  private} methods are truly ``secrets'', and 2) inferring which
method(s) an API test is intended to describe is often difficult and
outside the scope of this work.

According to our discipline (assuming the mocha developers had adopted
our discipline), the tests included with mocha version 1.0.0 would
pass when run against every version in the 1.X.Y range. There are 50
versions in this range. We found that 9\% of the jsapi tests from
version 1.0.0 (6 out of the 66) failed on subsequent versions.

Since mocha developers are not using our discipline, we expect some of
these failures to be due to not following the discipline; the test
depends (either explicitly or implicitly) upon API secrets. These
cases do not necessarily indicate SemVer violations, as long as the
removing the dependence on API secrets makes the tests pass. We
manually inspected each failing jsapi test for API secrets, and
refactored the test to remove the secret. {\bf Failure 1} below gives
an example of this.

We manually inspected of the 6 failing jsapi tests to identify the
cause of the failure and remove any API secrets. We found that 4 of
the 6 test failures were multiple instances of a single problem, so
there were 3 types of failure. Of the 3 failure types, 2 failed due to
testing secrets as well as the API, and the tests succeeded after
removing the exposed secrets. Altogether, the classification and
refactoring of these tests required 4 hours of effort by Matt, who was
unfamiliar with mocha's internals. We did not find any instances in
which a test could not be refactored. This experience demonstrates
that that adopting our discipline may not be too difficult.

We summarize the 3 failing jsapi tests, our diagnosis of the cause of
the failure (SemVer violation or exposed secret), and in the cases of
exposed secrets, the fix required for the test to conform to our
discipline.

\subsubsection{Failure 1: API test makes assertions about API secrets.}
{\bf Test description: } {\em Suite .beforeAll() wraps the passed in
function in a Hook adds it to \_beforeAll}
\label{sec:failure1}

\/There are three other tests that are very similar. Together, these
four tests describe the behavoir of event hook registration
functions. The {\tt Suite} class signals events at different stages of
executing a test suite: before running any tests (beforeAll), after
all tests have been run (afterAll), just before each test is run
(beforeEach), and just after each test is run (afterEach). Each event
has its corresponding event hook registration method, and each
registration method has its corresponding test case. The test case
ensures that the correct metadata is created for each event hook, that
the events are emitted in the correct order, etc.

Part of the metadata for an event hook is a title used in mocha's
output to the user. Each test asserts that the title is a particular
string.

{\small
\begin{verbatim}
beforeAllItem.title.should.equal('"before all" hook');
\end{verbatim}
}

Starting in version 1.15.0, mocha added a feature that allows the test
writer to optionally give a name to the hook, which is then included
in the title. If a title is not given, the default is to use the name
of the hook function. The test fails because the new default behavior
is not consistent with the old behavior.

We judge this not to be a SemVer violation, but rather a violation of
our testing discipline. The title of the hook is not meant to be part
of the client interface, just part of the report
formatting. Therefore, our discipline dictates that such an assertion
should not be made in an interface test, and should instead be moved
to an internal test.

In order to adopt our discipline, the mocha developers could duplicate
the test in two places, first in the API specification test suite, and
second in the internal test suite to check secrets like that the title
is constructed correctly. This would either require some code
duplication, or some refactoring of the test in order to reuse
code. There are the usual risks associated with each option:
duplicating code means that as the API evolves, the same changes must
be applied in two places; refactoring test code can make it more
complex, which might limit its benefit as a specification to client
developers.

\subsubsection{Failure 2: Error changes.}
\label{sec:failure2}
{\bf Test description: }
%
{\em Runnable(title, fn) .run(fn) when async when the callback is
  invoked several times with an error should emit a single "error"
  event }

\begin{figure*}
\begin{lstlisting}
describe('Runnable(title, fn)', function(){
  describe('.run(fn)', function(){
    describe('when async', function(){
      describe('when the callback is invoked several times', function(){
        describe('with an error', function(){
          it('should emit a single "error" event', function(done){
            var calls = 0;
            var errCalls = 0;

            var test = new Runnable('foo', function(done){
              done(new Error('fail'));
              process.nextTick(done);
              done(new Error('fail'));
              process.nextTick(done);
              process.nextTick(done);
            });

            test.on('error', function(err){
              ++errCalls;
              err.message.should.equal('done() called multiple times');
              calls.should.equal(1);
              errCalls.should.equal(1);
              done();
            });

            test.run(function(){
              ++calls;
            });
          })
        })
\end{lstlisting}
\caption{A failing mocha jsapi test}
\label{fig:failing-test}
\end{figure*}

This test is shown in Figure\~\ref{fig:failing-test}. The test defines
part of the behavior of mocha's asynchronous test runner, that when
two asyncronous error events are triggered, only one is delivered to
the error callback. This is important in tests that allocate resources
like database connections that need to be released exactly once.

In addition to testing that only a single error event is delivered,
the version 1.0.0 test also tests {\em which} error event is
delivered. In particular, line 20 tests that the error message is a
particular string. The behavior changes at version 1.3.0, from
delivering an error created by mocha that indicates improper usage of
its API, to one of the errors passed by the client to the callback.

It is this case a breaking change, a new feature, or something else?
We might consider that the exceptions thrown by mocha to its clients
are part of the API, and so this should be considered a breaking
change.  Given that the test author's intent is unclear, we follow the
test description, which mentions only the number of error events that
should be delivered. Therefore, we considered {\em which} error event
is delivered to be secret information, and removed it from the test
simply by deleting line 20.

\subsubsection{Failure 3: SemVer violation.}

{\bf Test description:}
%
{\em Runner .failHook(hoot, err) should emit "end" }

The method {\tt Runner.failHook} calls a failure hook, and after that
hook runs, emits an ``end'' event to allow test clean up to occur. In
version 1.21.5, whether the ``end'' event should be emitted became
configurable by setting the property {\tt suite.bail}.  The
description of this test was changed to reflect this:

{\em Runner .failHook(hoot, err) should emit "end" if suite bail is
  true }

The original test fails because the default value of suite.bail is
{\tt false}, so if a client upgrades mocha to version 1.21.5, the
``end'' event will no longer be emitted. This is a breaking change in
a patch version, and thus is a SemVer violation. We note that the {\tt
  Runner.failHook} method is annotated ``@api private'', so this test
may not actually be part of the API specification.

\subsubsection{Confounding Factors}
We identify three confounding factors with our user study. First, it
is still unclear that the ``jsapi'' tests should be used as mocha's
interface specification. These tests were identified by the mocha
developers as the ``Javascript API tests'', and among the Javascript
libraries we considered for our subject program, seemed to be the most
reasonable test suite to use as a specification. We assume that what
the mocha developers mean by ``API'' is the API between mocha and its
client. However, this may not always be the case. In practice, this
test suite tests internal interfaces as well as the external
client-facing interface.

A second confounding factor is the small sample size of our study:
only refactored one test suite version of one library. The scope was
limited by the effort required to get good cross-version test
results. Given more time, we would like to examine and refactor more
cross-version testing failures from Mocha other libraries.

A third confounding factor is that the quality of Mocha's test suite
is likely to be quite good compared with the average Javascript test
suite. This is to be expected, since Mocha itself is a test suite, so
its developers would be expected to be more ``pro-test'' than the
average developer. For this reason, Mocha's test suite may not be
representative of other test suites.


\todo{Mocha `test-all` runs many tests multiple times. Runs all
  categories, individual tests are included in more than one
  category. Remove duplicate test titles from total and failing
  tests. On the other hand, some distinct mocha tests have the same
  titles, so when we remove duplicate titles, we lose some of that
  information. There are fewer duplicate titles than tests that are
  re-run though, so we choose the thing that minimizes the error.}
